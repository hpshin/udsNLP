{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Transformer from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be implementing the famous Transformer architecture from scratch.\n",
    "\n",
    "The code is based off of the following repos/blog posts:\n",
    "\n",
    "- [attention-is-all-you-need-pytorch](https://github.com/jadore801120/attention-is-all-you-need-pytorch)\n",
    "- [pytorch-pretrained-BERT](https://github.com/huggingface/pytorch-pretrained-BERT)\n",
    "- [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html) \n",
    "\n",
    "Thanks so much to their authors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the keys to understanding how any model works is understanding how the shapes of the tensors change during the processing of each part. We'll be using the logging module to output debugging information to help our understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"tensor_shapes\")\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        '%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "# if you want the model to continuously print tensor shapes, set to DEBUG!\n",
    "logger.setLevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "def getclass():\n",
    "    stack = inspect.stack()\n",
    "    return stack[3][0].f_locals[\"self\"].__class__\n",
    "\n",
    "# A helper function to check how tensor sizes change\n",
    "def log_size(tsr: torch.Tensor, name: str):\n",
    "    cls = getclass()\n",
    "    logger.log(level=cls.level, msg=f\"[{cls.__name__}] {name} size={tsr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use logging levels to control the modules we receive output from. The lower the logging level, the more tensor information you'll get. Feel free to play around!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "# Control how much debugging output we want\n",
    "class TensorLoggingLevels(IntEnum):\n",
    "    attention = 1\n",
    "    attention_head = 2\n",
    "    multihead_attention_block = 3\n",
    "    enc_dec_block = 4\n",
    "    enc_dec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using an enum to refer to dimensions whenever possible to improve readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dim(IntEnum):\n",
    "    batch = 0\n",
    "    seq = 1\n",
    "    feature = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Transformer is an attention-based architecture. The attention used in the Transformer is the scaled dot product attention, represented by the following formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textrm{Attention}(Q, K, V) = \\textrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i2.wp.com/mlexplained.com/wp-content/uploads/2017/12/scaled_dot_product_attention.png?zoom=2&w=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    level = TensorLoggingLevels.attention # Logging level: \n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        d_k = k.size(-1) # get the size of the key\n",
    "        assert q.size(-1) == d_k\n",
    "\n",
    "        # compute the dot product between queries and keys for\n",
    "        # each batch and position in the sequence\n",
    "        attn = torch.bmm(q, k.transpose(Dim.seq, Dim.feature)) # (Batch, Seq, Seq)\n",
    "        # we get an attention score between each position in the sequence\n",
    "        # for each batch\n",
    "\n",
    "        # scale the dot products by the dimensionality (see the paper for why we do this!)\n",
    "        attn = attn / math.sqrt(d_k)\n",
    "        # normalize the weights across the sequence dimension\n",
    "        # (Note that since we transposed, the sequence and feature dimensions are switched)\n",
    "        attn = torch.exp(attn)\n",
    "        log_size(attn, \"attention weight\") # (Batch, Seq, Seq)\n",
    "        \n",
    "        # fill attention weights with 0s where padded\n",
    "        if mask is not None: attn = attn.masked_fill(mask, 0)\n",
    "        attn = attn / attn.sum(dim=-1, keepdim=True)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v) # (Batch, Seq, Feature)\n",
    "        log_size(output, \"attention output size\") # (Batch, Seq, Seq)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = ScaledDotProductAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand(5, 10, 20)\n",
    "k = torch.rand(5, 10, 20)\n",
    "v = torch.rand(5, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ScaledDotProductAttention] attention weight size=torch.Size([5, 10, 10])\n",
      "[ScaledDotProductAttention] attention output size size=torch.Size([5, 10, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4155, 0.5476, 0.5082, 0.2934, 0.5051, 0.4386, 0.3601, 0.5725,\n",
       "          0.6110, 0.4794, 0.5212, 0.5381, 0.3694, 0.4678, 0.5721, 0.4100,\n",
       "          0.5772, 0.6029, 0.4823, 0.5055],\n",
       "         [0.4003, 0.4914, 0.4948, 0.3152, 0.4737, 0.5248, 0.4424, 0.5263,\n",
       "          0.5571, 0.4967, 0.5839, 0.4387, 0.4047, 0.4821, 0.5940, 0.3094,\n",
       "          0.4735, 0.5127, 0.4548, 0.4922],\n",
       "         [0.4476, 0.4908, 0.5069, 0.3254, 0.4825, 0.5062, 0.4613, 0.6021,\n",
       "          0.5678, 0.5532, 0.5904, 0.4289, 0.4781, 0.4523, 0.6046, 0.4032,\n",
       "          0.5579, 0.6051, 0.4195, 0.5306],\n",
       "         [0.1954, 0.3446, 0.2871, 0.1605, 0.3742, 0.2639, 0.2238, 0.3539,\n",
       "          0.4962, 0.3058, 0.3466, 0.3992, 0.2556, 0.3081, 0.4143, 0.3448,\n",
       "          0.4521, 0.4266, 0.2886, 0.2991],\n",
       "         [0.4436, 0.5463, 0.5449, 0.3344, 0.5127, 0.5633, 0.4302, 0.5472,\n",
       "          0.6020, 0.5208, 0.6171, 0.4898, 0.4234, 0.5031, 0.6462, 0.3333,\n",
       "          0.4936, 0.5137, 0.5001, 0.4946],\n",
       "         [0.3570, 0.4294, 0.3758, 0.2352, 0.4185, 0.3467, 0.4334, 0.5752,\n",
       "          0.5453, 0.3906, 0.4847, 0.3604, 0.3293, 0.3968, 0.4930, 0.3859,\n",
       "          0.4357, 0.4923, 0.4123, 0.4794],\n",
       "         [0.4528, 0.5879, 0.5346, 0.3287, 0.5520, 0.5377, 0.4628, 0.6572,\n",
       "          0.6927, 0.5883, 0.6204, 0.5482, 0.4660, 0.4969, 0.6505, 0.4388,\n",
       "          0.5805, 0.6449, 0.5132, 0.5826],\n",
       "         [0.4560, 0.4897, 0.5122, 0.3264, 0.4832, 0.5043, 0.4670, 0.6036,\n",
       "          0.5666, 0.5435, 0.5920, 0.4228, 0.4658, 0.4677, 0.6120, 0.4044,\n",
       "          0.5558, 0.5986, 0.4269, 0.5276],\n",
       "         [0.3863, 0.5662, 0.4789, 0.3185, 0.4919, 0.5337, 0.4406, 0.6050,\n",
       "          0.6278, 0.6031, 0.5557, 0.5154, 0.4620, 0.4188, 0.5651, 0.3371,\n",
       "          0.4917, 0.6356, 0.4356, 0.5598],\n",
       "         [0.4594, 0.5924, 0.5375, 0.3329, 0.5309, 0.5502, 0.4660, 0.6625,\n",
       "          0.6740, 0.5926, 0.6405, 0.5330, 0.4645, 0.5119, 0.6526, 0.4198,\n",
       "          0.5770, 0.6295, 0.5197, 0.5818]],\n",
       "\n",
       "        [[0.4051, 0.5443, 0.6538, 0.5081, 0.3729, 0.5752, 0.5056, 0.4676,\n",
       "          0.5606, 0.4854, 0.4951, 0.3981, 0.4025, 0.3629, 0.4845, 0.4832,\n",
       "          0.4724, 0.3937, 0.5399, 0.4530],\n",
       "         [0.3707, 0.5392, 0.5625, 0.4742, 0.4333, 0.5978, 0.5418, 0.5099,\n",
       "          0.5672, 0.4953, 0.4786, 0.4153, 0.3954, 0.3861, 0.4326, 0.5351,\n",
       "          0.4739, 0.3852, 0.5374, 0.4304],\n",
       "         [0.4170, 0.6367, 0.6665, 0.5222, 0.4727, 0.6177, 0.6283, 0.5268,\n",
       "          0.6889, 0.5907, 0.5958, 0.4966, 0.4215, 0.4088, 0.5251, 0.5902,\n",
       "          0.5542, 0.4620, 0.6515, 0.5506],\n",
       "         [0.3777, 0.5487, 0.5789, 0.5022, 0.4328, 0.5992, 0.5571, 0.5144,\n",
       "          0.5835, 0.5052, 0.4985, 0.4268, 0.3982, 0.3878, 0.4110, 0.5318,\n",
       "          0.4762, 0.3976, 0.5612, 0.4500],\n",
       "         [0.3305, 0.5475, 0.5822, 0.4432, 0.4226, 0.4928, 0.6334, 0.5046,\n",
       "          0.6612, 0.5583, 0.5721, 0.4712, 0.3576, 0.3237, 0.4619, 0.5091,\n",
       "          0.4774, 0.4080, 0.5920, 0.4812],\n",
       "         [0.3541, 0.3958, 0.4381, 0.4304, 0.3982, 0.4672, 0.4291, 0.4229,\n",
       "          0.4962, 0.4105, 0.4628, 0.3349, 0.2335, 0.2965, 0.2689, 0.4077,\n",
       "          0.4043, 0.2732, 0.4760, 0.4186],\n",
       "         [0.4024, 0.5573, 0.6615, 0.5200, 0.3777, 0.5673, 0.5296, 0.4754,\n",
       "          0.5872, 0.5003, 0.5175, 0.4028, 0.4084, 0.3595, 0.5051, 0.4851,\n",
       "          0.4870, 0.4081, 0.5552, 0.4714],\n",
       "         [0.4023, 0.5419, 0.5528, 0.4209, 0.4484, 0.4984, 0.5481, 0.4503,\n",
       "          0.5297, 0.5206, 0.4805, 0.4332, 0.3457, 0.3555, 0.4989, 0.5393,\n",
       "          0.4953, 0.3905, 0.5289, 0.4152],\n",
       "         [0.4111, 0.6303, 0.6610, 0.5351, 0.4734, 0.6231, 0.6214, 0.5194,\n",
       "          0.6948, 0.5919, 0.5947, 0.4863, 0.4281, 0.4179, 0.5025, 0.5868,\n",
       "          0.5514, 0.4671, 0.6638, 0.5534],\n",
       "         [0.3236, 0.5350, 0.5076, 0.4680, 0.2526, 0.4713, 0.4007, 0.3393,\n",
       "          0.4409, 0.3341, 0.3826, 0.3111, 0.3318, 0.2862, 0.3738, 0.3915,\n",
       "          0.3975, 0.3921, 0.4620, 0.4642]],\n",
       "\n",
       "        [[0.4761, 0.5367, 0.5736, 0.3884, 0.2864, 0.3155, 0.3995, 0.4898,\n",
       "          0.4415, 0.4629, 0.4939, 0.3740, 0.4662, 0.4615, 0.4588, 0.4146,\n",
       "          0.3094, 0.3553, 0.2609, 0.3692],\n",
       "         [0.4346, 0.5251, 0.5411, 0.3622, 0.3435, 0.3287, 0.4175, 0.4901,\n",
       "          0.4483, 0.4450, 0.5608, 0.3869, 0.4606, 0.4382, 0.4781, 0.4096,\n",
       "          0.3131, 0.3949, 0.2565, 0.2944],\n",
       "         [0.4991, 0.5616, 0.6459, 0.4571, 0.3087, 0.3697, 0.3943, 0.5252,\n",
       "          0.4569, 0.5236, 0.5177, 0.4687, 0.4549, 0.4712, 0.4758, 0.4725,\n",
       "          0.3973, 0.3914, 0.2927, 0.4104],\n",
       "         [0.5474, 0.6674, 0.6873, 0.5463, 0.3595, 0.4464, 0.4630, 0.5832,\n",
       "          0.5027, 0.5705, 0.5901, 0.5333, 0.5297, 0.5626, 0.5783, 0.5311,\n",
       "          0.4895, 0.4946, 0.3908, 0.4264],\n",
       "         [0.5086, 0.6555, 0.6783, 0.5047, 0.2897, 0.4297, 0.3619, 0.4907,\n",
       "          0.5041, 0.5121, 0.5303, 0.4951, 0.4713, 0.4484, 0.4707, 0.5037,\n",
       "          0.4675, 0.4690, 0.3772, 0.4341],\n",
       "         [0.4526, 0.6404, 0.6273, 0.4984, 0.3830, 0.3674, 0.4089, 0.5048,\n",
       "          0.4878, 0.4690, 0.5807, 0.5395, 0.4430, 0.4748, 0.5203, 0.5105,\n",
       "          0.4656, 0.4222, 0.3821, 0.4088],\n",
       "         [0.5293, 0.6592, 0.6774, 0.5306, 0.3859, 0.4410, 0.4768, 0.6028,\n",
       "          0.4995, 0.5573, 0.5992, 0.5392, 0.5158, 0.5653, 0.5900, 0.5361,\n",
       "          0.4798, 0.4858, 0.3818, 0.4116],\n",
       "         [0.5432, 0.6672, 0.7046, 0.5435, 0.3673, 0.4676, 0.4470, 0.5939,\n",
       "          0.5077, 0.5638, 0.5912, 0.5550, 0.5053, 0.5426, 0.5623, 0.5448,\n",
       "          0.5038, 0.5061, 0.3926, 0.4355],\n",
       "         [0.5348, 0.6641, 0.6949, 0.5416, 0.3795, 0.4525, 0.4594, 0.5928,\n",
       "          0.5042, 0.5619, 0.5935, 0.5482, 0.5083, 0.5539, 0.5743, 0.5487,\n",
       "          0.4901, 0.4911, 0.3890, 0.4221],\n",
       "         [0.4700, 0.5726, 0.6455, 0.4602, 0.3783, 0.4092, 0.4227, 0.5247,\n",
       "          0.4878, 0.5470, 0.5964, 0.4845, 0.4634, 0.4556, 0.5143, 0.5211,\n",
       "          0.4014, 0.4510, 0.3068, 0.3431]],\n",
       "\n",
       "        [[0.5445, 0.3971, 0.7460, 0.6845, 0.5442, 0.7100, 0.5961, 0.5472,\n",
       "          0.4296, 0.6696, 0.5938, 0.5324, 0.4668, 0.4381, 0.5990, 0.6275,\n",
       "          0.5264, 0.5756, 0.5574, 0.6756],\n",
       "         [0.3550, 0.2729, 0.5539, 0.4732, 0.4366, 0.4733, 0.4165, 0.4229,\n",
       "          0.2765, 0.4505, 0.4626, 0.4240, 0.3414, 0.3176, 0.5126, 0.4446,\n",
       "          0.3568, 0.4599, 0.4004, 0.4710],\n",
       "         [0.5493, 0.4130, 0.7480, 0.6883, 0.5368, 0.7191, 0.6061, 0.5553,\n",
       "          0.4425, 0.6717, 0.5995, 0.5420, 0.4524, 0.4584, 0.5908, 0.6210,\n",
       "          0.5289, 0.5601, 0.5591, 0.6750],\n",
       "         [0.5473, 0.4165, 0.7490, 0.6836, 0.5395, 0.7110, 0.6159, 0.5514,\n",
       "          0.4170, 0.6715, 0.5943, 0.5286, 0.4714, 0.4457, 0.5937, 0.6197,\n",
       "          0.5339, 0.5706, 0.5500, 0.6730],\n",
       "         [0.3843, 0.3299, 0.6374, 0.4882, 0.3881, 0.5300, 0.5009, 0.4595,\n",
       "          0.3735, 0.4930, 0.4248, 0.3848, 0.2845, 0.3294, 0.4428, 0.3894,\n",
       "          0.3695, 0.4428, 0.3854, 0.5274],\n",
       "         [0.4896, 0.4119, 0.6406, 0.6434, 0.5101, 0.6388, 0.5312, 0.5106,\n",
       "          0.3737, 0.6134, 0.5434, 0.5245, 0.4260, 0.4418, 0.4963, 0.5513,\n",
       "          0.4953, 0.4700, 0.5088, 0.5484],\n",
       "         [0.5359, 0.3054, 0.6755, 0.6164, 0.5117, 0.6518, 0.5158, 0.5017,\n",
       "          0.3953, 0.5845, 0.5652, 0.5082, 0.3943, 0.4210, 0.5400, 0.6368,\n",
       "          0.4578, 0.4898, 0.4883, 0.6090],\n",
       "         [0.4094, 0.4076, 0.6172, 0.4832, 0.3679, 0.5556, 0.5148, 0.4465,\n",
       "          0.3637, 0.5290, 0.5213, 0.4342, 0.3399, 0.4001, 0.5128, 0.3870,\n",
       "          0.4056, 0.4469, 0.4116, 0.5556],\n",
       "         [0.5304, 0.4056, 0.6696, 0.6345, 0.4832, 0.6844, 0.5752, 0.5007,\n",
       "          0.3977, 0.6351, 0.5284, 0.4995, 0.4344, 0.4267, 0.5242, 0.5774,\n",
       "          0.5086, 0.4806, 0.5145, 0.6380],\n",
       "         [0.5252, 0.3114, 0.6828, 0.6116, 0.5125, 0.6459, 0.5214, 0.5127,\n",
       "          0.3991, 0.5773, 0.5561, 0.5107, 0.3793, 0.4218, 0.5361, 0.6187,\n",
       "          0.4513, 0.4859, 0.4823, 0.6026]],\n",
       "\n",
       "        [[0.3147, 0.3000, 0.2786, 0.3033, 0.2615, 0.2448, 0.2961, 0.3627,\n",
       "          0.3235, 0.3345, 0.2791, 0.3841, 0.3252, 0.3385, 0.3391, 0.4363,\n",
       "          0.3026, 0.3184, 0.1900, 0.2674],\n",
       "         [0.6533, 0.5637, 0.5781, 0.5510, 0.4616, 0.5324, 0.5176, 0.5125,\n",
       "          0.5654, 0.5811, 0.5956, 0.5501, 0.5678, 0.7071, 0.4841, 0.7797,\n",
       "          0.6326, 0.6013, 0.3636, 0.4996],\n",
       "         [0.6035, 0.5136, 0.5249, 0.4747, 0.4404, 0.4292, 0.4350, 0.4988,\n",
       "          0.4520, 0.5083, 0.5581, 0.5310, 0.5078, 0.5945, 0.4537, 0.6917,\n",
       "          0.5628, 0.5981, 0.3432, 0.4394],\n",
       "         [0.5038, 0.4582, 0.4565, 0.4375, 0.3142, 0.5047, 0.4446, 0.4409,\n",
       "          0.5113, 0.4747, 0.4990, 0.4499, 0.3817, 0.6092, 0.3772, 0.6978,\n",
       "          0.5055, 0.4499, 0.2680, 0.3921],\n",
       "         [0.6597, 0.5716, 0.5750, 0.5608, 0.4584, 0.5223, 0.5180, 0.5131,\n",
       "          0.5571, 0.5904, 0.5911, 0.5330, 0.5772, 0.6903, 0.4682, 0.7829,\n",
       "          0.6306, 0.6058, 0.3523, 0.4994],\n",
       "         [0.6624, 0.5655, 0.5734, 0.5571, 0.4602, 0.5360, 0.5182, 0.5133,\n",
       "          0.5594, 0.5825, 0.5974, 0.5558, 0.5722, 0.7072, 0.4741, 0.7863,\n",
       "          0.6422, 0.6092, 0.3640, 0.4898],\n",
       "         [0.5989, 0.5507, 0.5370, 0.4523, 0.3859, 0.4616, 0.4748, 0.4180,\n",
       "          0.4926, 0.5334, 0.5157, 0.4548, 0.5189, 0.5944, 0.4541, 0.6986,\n",
       "          0.5349, 0.5867, 0.2519, 0.5004],\n",
       "         [0.5540, 0.5167, 0.4654, 0.4840, 0.3807, 0.5269, 0.4663, 0.4900,\n",
       "          0.5457, 0.5055, 0.4837, 0.5361, 0.4977, 0.6624, 0.4100, 0.7477,\n",
       "          0.5713, 0.5214, 0.3055, 0.4029],\n",
       "         [0.6493, 0.5204, 0.4774, 0.5201, 0.4294, 0.4635, 0.4717, 0.4699,\n",
       "          0.4655, 0.5344, 0.5772, 0.4862, 0.5289, 0.5931, 0.3960, 0.7315,\n",
       "          0.6227, 0.6077, 0.3302, 0.4387],\n",
       "         [0.6525, 0.5619, 0.5779, 0.5406, 0.4360, 0.5535, 0.5288, 0.5091,\n",
       "          0.5683, 0.5824, 0.6001, 0.5655, 0.5480, 0.7125, 0.4889, 0.7953,\n",
       "          0.6274, 0.6028, 0.3461, 0.4935]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we turn to the core component in the Transformer architecture: the multi-head attention block. This block applies linear transformations to the input, then applies scaled dot product attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i2.wp.com/mlexplained.com/wp-content/uploads/2017/12/multi_head_attention.png?zoom=2&resize=224%2C293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    level = TensorLoggingLevels.attention_head\n",
    "    def __init__(self, d_model, d_feature, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # We will assume the queries, keys, and values all have the same feature size\n",
    "        self.attn = ScaledDotProductAttention(dropout)\n",
    "        self.query_tfm = nn.Linear(d_model, d_feature)\n",
    "        self.key_tfm = nn.Linear(d_model, d_feature)\n",
    "        self.value_tfm = nn.Linear(d_model, d_feature)\n",
    "\n",
    "    def forward(self, queries, keys, values, mask=None):\n",
    "        Q = self.query_tfm(queries) # (Batch, Seq, Feature)\n",
    "        K = self.key_tfm(keys) # (Batch, Seq, Feature)\n",
    "        V = self.value_tfm(values) # (Batch, Seq, Feature)\n",
    "        log_size(Q, \"queries, keys, vals\")\n",
    "        # compute multiple attention weighted sums\n",
    "        x = self.attn(Q, K, V)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[ScaledDotProductAttention] attention weight size=torch.Size([5, 10, 10])\n",
      "[ScaledDotProductAttention] attention output size size=torch.Size([5, 10, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.6996e-01,  1.8375e-04,  9.1657e-01, -2.1066e-01, -3.7544e-03,\n",
       "          -4.2488e-01, -4.4396e-02, -4.1814e-01, -1.4343e-01,  6.8965e-01,\n",
       "          -2.8909e-01,  2.2854e-01,  6.5507e-01,  5.3401e-01,  2.6055e-01,\n",
       "           4.5195e-02, -3.3342e-01, -2.5821e-01,  4.8853e-01, -7.6121e-01],\n",
       "         [-2.6549e-01,  4.9494e-03,  9.1689e-01, -2.1464e-01, -2.4507e-03,\n",
       "          -4.2283e-01, -4.4367e-02, -4.1772e-01, -1.3946e-01,  6.8473e-01,\n",
       "          -2.8738e-01,  2.2760e-01,  6.5208e-01,  5.3310e-01,  2.5720e-01,\n",
       "           4.1898e-02, -3.3669e-01, -2.5638e-01,  4.8931e-01, -7.6089e-01],\n",
       "         [-2.5423e-01,  1.6306e-02,  8.4685e-01, -2.0307e-01,  2.9387e-02,\n",
       "          -4.0364e-01, -3.1224e-02, -3.8628e-01, -1.5168e-01,  6.4818e-01,\n",
       "          -2.7544e-01,  2.1792e-01,  5.7187e-01,  5.1569e-01,  2.7195e-01,\n",
       "           5.3186e-02, -2.8877e-01, -2.3342e-01,  4.4399e-01, -7.0993e-01],\n",
       "         [-2.6786e-01,  4.8589e-03,  9.1855e-01, -2.1370e-01, -4.9534e-04,\n",
       "          -4.2614e-01, -4.5102e-02, -4.2156e-01, -1.4466e-01,  6.8901e-01,\n",
       "          -2.9313e-01,  2.2769e-01,  6.5328e-01,  5.3729e-01,  2.6359e-01,\n",
       "           4.3301e-02, -3.3437e-01, -2.5631e-01,  4.9190e-01, -7.6748e-01],\n",
       "         [-2.7039e-01,  5.5770e-04,  9.1559e-01, -2.1115e-01, -2.4482e-03,\n",
       "          -4.2639e-01, -4.5591e-02, -4.2095e-01, -1.4480e-01,  6.9395e-01,\n",
       "          -2.9397e-01,  2.2704e-01,  6.5601e-01,  5.3844e-01,  2.6623e-01,\n",
       "           4.7743e-02, -3.3014e-01, -2.5615e-01,  4.8917e-01, -7.6869e-01],\n",
       "         [-2.6832e-01,  2.3947e-03,  9.1850e-01, -2.1281e-01, -2.0169e-03,\n",
       "          -4.2527e-01, -4.5263e-02, -4.2143e-01, -1.4291e-01,  6.8954e-01,\n",
       "          -2.9238e-01,  2.2722e-01,  6.5405e-01,  5.3696e-01,  2.6232e-01,\n",
       "           4.3764e-02, -3.3374e-01, -2.5701e-01,  4.9002e-01, -7.6706e-01],\n",
       "         [-2.2567e-01,  1.6930e-02,  7.5635e-01, -1.7568e-01,  4.6092e-02,\n",
       "          -3.5130e-01, -2.6754e-02, -3.5379e-01, -1.4818e-01,  5.5130e-01,\n",
       "          -2.5231e-01,  1.8477e-01,  4.9788e-01,  4.5641e-01,  2.4514e-01,\n",
       "           3.4553e-02, -2.3614e-01, -2.1660e-01,  4.1763e-01, -6.2898e-01],\n",
       "         [-2.4228e-01,  1.9143e-02,  7.2302e-01, -1.6136e-01,  3.4777e-02,\n",
       "          -3.7483e-01, -3.0802e-02, -3.3154e-01, -1.7147e-01,  6.0775e-01,\n",
       "          -2.5663e-01,  1.9334e-01,  5.1925e-01,  4.5670e-01,  2.7923e-01,\n",
       "           7.4699e-02, -2.2871e-01, -1.9674e-01,  4.0981e-01, -6.3023e-01],\n",
       "         [-2.3751e-01,  8.6483e-03,  8.2710e-01, -1.9915e-01, -5.8403e-03,\n",
       "          -3.7760e-01, -4.4324e-02, -3.6287e-01, -1.1938e-01,  6.0189e-01,\n",
       "          -2.3560e-01,  2.1657e-01,  5.8799e-01,  4.5719e-01,  2.0987e-01,\n",
       "           3.8179e-02, -3.0971e-01, -2.4368e-01,  4.3561e-01, -6.4834e-01],\n",
       "         [-2.0803e-01, -3.4602e-02,  7.1804e-01, -1.5805e-01,  3.4393e-03,\n",
       "          -3.0185e-01, -3.9539e-02, -3.5664e-01, -9.6208e-02,  5.0419e-01,\n",
       "          -2.4080e-01,  1.5644e-01,  5.3023e-01,  4.2527e-01,  2.0138e-01,\n",
       "           2.8192e-02, -2.1348e-01, -2.2210e-01,  4.0166e-01, -6.1848e-01]],\n",
       "\n",
       "        [[-3.1021e-01,  1.2804e-02,  8.3440e-01, -1.5628e-01,  9.9348e-02,\n",
       "          -3.6459e-01, -1.5822e-01, -3.7547e-01, -1.0524e-01,  5.5766e-01,\n",
       "          -2.8453e-01,  1.0965e-01,  6.1843e-01,  5.6594e-01,  1.8364e-01,\n",
       "           1.4780e-01, -3.9227e-01, -1.9451e-01,  4.3075e-01, -7.6093e-01],\n",
       "         [-3.0884e-01,  1.1028e-02,  8.3440e-01, -1.5562e-01,  9.6521e-02,\n",
       "          -3.6298e-01, -1.5950e-01, -3.7704e-01, -1.0155e-01,  5.5645e-01,\n",
       "          -2.8599e-01,  1.0876e-01,  6.1805e-01,  5.6687e-01,  1.8262e-01,\n",
       "           1.4791e-01, -3.9228e-01, -1.9312e-01,  4.2856e-01, -7.6131e-01],\n",
       "         [-2.4375e-01,  2.5314e-02,  5.2662e-01, -1.5588e-01,  8.0183e-02,\n",
       "          -2.7766e-01, -5.6560e-02, -2.0723e-01, -4.2008e-02,  3.8601e-01,\n",
       "          -2.1559e-01,  5.5026e-02,  3.9908e-01,  4.5514e-01,  1.2839e-01,\n",
       "           7.5532e-02, -2.8937e-01, -1.1434e-01,  2.7629e-01, -4.9879e-01],\n",
       "         [-2.8655e-01,  2.6136e-02,  7.7032e-01, -1.3956e-01,  1.1235e-01,\n",
       "          -3.2842e-01, -1.1095e-01, -3.3337e-01, -1.2972e-01,  5.0412e-01,\n",
       "          -2.3771e-01,  1.1057e-01,  5.5516e-01,  5.0471e-01,  2.0112e-01,\n",
       "           1.0958e-01, -3.3617e-01, -1.8241e-01,  3.9583e-01, -6.8557e-01],\n",
       "         [-1.8087e-01,  2.7205e-02,  4.8229e-01, -9.0491e-02,  1.0525e-01,\n",
       "          -2.1964e-01, -6.4730e-02, -2.0423e-01, -9.2402e-02,  3.1777e-01,\n",
       "          -1.5312e-01,  6.9608e-02,  3.1545e-01,  3.1083e-01,  9.5403e-02,\n",
       "           4.4780e-02, -2.7226e-01, -1.1871e-01,  2.5221e-01, -4.4296e-01],\n",
       "         [-2.5818e-01,  1.2195e-02,  7.6423e-01, -1.2109e-01,  6.3556e-02,\n",
       "          -3.1199e-01, -1.5399e-01, -3.4311e-01, -6.6419e-02,  4.9646e-01,\n",
       "          -2.5316e-01,  9.5760e-02,  5.5290e-01,  5.2014e-01,  1.8029e-01,\n",
       "           1.2974e-01, -3.2899e-01, -1.4164e-01,  3.7898e-01, -6.7404e-01],\n",
       "         [-2.7147e-01, -1.4597e-03,  7.5367e-01, -1.1415e-01,  9.5833e-02,\n",
       "          -3.0943e-01, -1.4160e-01, -3.4257e-01, -8.5589e-02,  4.8968e-01,\n",
       "          -2.4631e-01,  8.7450e-02,  5.2883e-01,  4.8833e-01,  1.2717e-01,\n",
       "           1.2346e-01, -3.9074e-01, -1.6933e-01,  3.8053e-01, -6.8371e-01],\n",
       "         [-2.3416e-01,  1.9166e-02,  6.8582e-01, -1.3445e-01,  9.3683e-02,\n",
       "          -3.0372e-01, -1.5002e-01, -3.0381e-01, -8.7858e-02,  4.2813e-01,\n",
       "          -2.5368e-01,  9.9260e-02,  4.8320e-01,  4.5099e-01,  1.3050e-01,\n",
       "           1.3521e-01, -3.3992e-01, -1.4492e-01,  3.4852e-01, -6.0565e-01],\n",
       "         [-3.0864e-01,  1.0740e-02,  8.3280e-01, -1.5493e-01,  9.6414e-02,\n",
       "          -3.6282e-01, -1.6006e-01, -3.7592e-01, -1.0105e-01,  5.5594e-01,\n",
       "          -2.8413e-01,  1.0865e-01,  6.1709e-01,  5.6556e-01,  1.8107e-01,\n",
       "           1.4756e-01, -3.9226e-01, -1.9316e-01,  4.2862e-01, -7.5988e-01],\n",
       "         [-2.5820e-01,  6.1780e-03,  6.4147e-01, -1.5264e-01,  7.6115e-02,\n",
       "          -2.9121e-01, -8.0890e-02, -2.7204e-01, -4.3180e-02,  4.1294e-01,\n",
       "          -2.3412e-01,  7.8135e-02,  4.4992e-01,  4.9507e-01,  1.5037e-01,\n",
       "           7.1380e-02, -3.1939e-01, -1.3564e-01,  2.9943e-01, -5.8320e-01]],\n",
       "\n",
       "        [[-3.4667e-01,  2.4305e-03,  9.0130e-01, -2.2325e-01,  3.4931e-02,\n",
       "          -3.9506e-01, -4.4996e-02, -3.9620e-01, -7.8632e-02,  5.7399e-01,\n",
       "          -2.6756e-01,  1.6462e-01,  5.4316e-01,  5.6808e-01,  2.3863e-01,\n",
       "           6.4013e-02, -3.7437e-01, -1.9467e-01,  4.0001e-01, -6.9304e-01],\n",
       "         [-3.4693e-01,  2.0450e-03,  9.0397e-01, -2.2046e-01,  3.8137e-02,\n",
       "          -3.9566e-01, -4.5287e-02, -3.9834e-01, -8.0798e-02,  5.7337e-01,\n",
       "          -2.6915e-01,  1.6368e-01,  5.4277e-01,  5.7040e-01,  2.3909e-01,\n",
       "           6.2375e-02, -3.7760e-01, -1.9405e-01,  4.0097e-01, -6.9540e-01],\n",
       "         [-2.6841e-01,  2.0896e-02,  6.8629e-01, -2.0388e-01,  3.8661e-02,\n",
       "          -3.0671e-01, -3.1082e-02, -2.8525e-01, -4.9080e-02,  4.1187e-01,\n",
       "          -2.2280e-01,  1.1980e-01,  4.3523e-01,  4.6288e-01,  2.0084e-01,\n",
       "           6.4107e-02, -3.1512e-01, -1.3490e-01,  3.0199e-01, -5.3552e-01],\n",
       "         [-2.9714e-01,  1.2843e-03,  8.1780e-01, -1.7188e-01,  5.2139e-02,\n",
       "          -3.5461e-01, -4.4827e-02, -3.6571e-01, -7.8603e-02,  5.1249e-01,\n",
       "          -2.6364e-01,  1.3682e-01,  4.8030e-01,  5.2895e-01,  2.3764e-01,\n",
       "           5.5662e-02, -3.4972e-01, -1.4826e-01,  3.5489e-01, -6.3533e-01],\n",
       "         [-3.0360e-01,  6.2247e-03,  8.3420e-01, -2.0403e-01,  6.6814e-02,\n",
       "          -3.5832e-01, -3.4810e-02, -3.4767e-01, -8.3427e-02,  4.8483e-01,\n",
       "          -2.3914e-01,  1.6538e-01,  4.6730e-01,  5.1316e-01,  2.0370e-01,\n",
       "           3.8391e-02, -3.6991e-01, -1.8541e-01,  3.5329e-01, -6.2734e-01],\n",
       "         [-3.3892e-01,  3.0574e-03,  8.0308e-01, -2.2131e-01,  2.3657e-02,\n",
       "          -3.6607e-01, -4.5343e-02, -3.4694e-01, -7.8863e-02,  5.4135e-01,\n",
       "          -2.5797e-01,  1.4279e-01,  4.9814e-01,  5.3526e-01,  2.2127e-01,\n",
       "           9.6929e-02, -3.2514e-01, -1.8514e-01,  3.7311e-01, -6.0674e-01],\n",
       "         [-3.2238e-01,  8.2463e-04,  8.0647e-01, -1.8518e-01,  8.1934e-02,\n",
       "          -3.6874e-01, -3.6443e-02, -3.6111e-01, -1.0860e-01,  5.2925e-01,\n",
       "          -2.3756e-01,  1.5455e-01,  4.7552e-01,  4.9730e-01,  2.2687e-01,\n",
       "           7.9931e-02, -3.5803e-01, -1.8491e-01,  3.6164e-01, -6.2761e-01],\n",
       "         [-3.0131e-01,  9.6633e-03,  8.0814e-01, -2.0464e-01,  4.0408e-03,\n",
       "          -3.5253e-01, -2.8625e-02, -3.3482e-01, -5.3754e-02,  5.5094e-01,\n",
       "          -2.2558e-01,  1.5754e-01,  4.8156e-01,  4.9623e-01,  2.3217e-01,\n",
       "           5.5367e-02, -2.8580e-01, -1.7033e-01,  3.5165e-01, -6.1874e-01],\n",
       "         [-3.4516e-01,  1.6520e-02,  8.0609e-01, -1.9824e-01,  2.6251e-02,\n",
       "          -3.5115e-01, -5.4205e-02, -3.6884e-01, -7.6267e-02,  5.2227e-01,\n",
       "          -2.4344e-01,  1.0720e-01,  4.9451e-01,  5.3956e-01,  2.2313e-01,\n",
       "           5.8300e-02, -3.2356e-01, -1.6166e-01,  3.7386e-01, -6.3744e-01],\n",
       "         [-3.4663e-01,  1.7179e-02,  8.0947e-01, -2.0039e-01,  2.8226e-02,\n",
       "          -3.5268e-01, -5.4887e-02, -3.6921e-01, -7.7179e-02,  5.2254e-01,\n",
       "          -2.4353e-01,  1.0914e-01,  4.9427e-01,  5.4051e-01,  2.2345e-01,\n",
       "           5.9235e-02, -3.2557e-01, -1.6321e-01,  3.7408e-01, -6.3917e-01]],\n",
       "\n",
       "        [[-3.0122e-01, -9.7456e-02,  8.8040e-01, -2.0471e-01, -1.4389e-02,\n",
       "          -3.2501e-01, -1.3207e-01, -5.0588e-01, -2.0258e-02,  5.1782e-01,\n",
       "          -3.0918e-01,  8.6110e-02,  7.0630e-01,  6.1015e-01,  1.2033e-01,\n",
       "           8.9889e-02, -4.8544e-01, -1.8835e-01,  4.2295e-01, -7.7974e-01],\n",
       "         [-3.0137e-01, -9.8878e-02,  8.7998e-01, -2.0579e-01, -1.4512e-02,\n",
       "          -3.2524e-01, -1.3034e-01, -5.0507e-01, -1.9303e-02,  5.1723e-01,\n",
       "          -3.1110e-01,  8.5226e-02,  7.0738e-01,  6.1234e-01,  1.2104e-01,\n",
       "           9.0471e-02, -4.8594e-01, -1.8701e-01,  4.2449e-01, -7.7918e-01],\n",
       "         [-2.3522e-01, -7.6073e-02,  5.5055e-01, -1.5489e-01, -8.6866e-03,\n",
       "          -2.4295e-01, -1.4474e-02, -3.2576e-01,  3.9825e-03,  3.6565e-01,\n",
       "          -2.1843e-01,  2.5848e-02,  4.7486e-01,  5.1101e-01,  1.1940e-01,\n",
       "           2.4735e-02, -3.7821e-01, -7.9100e-02,  2.8578e-01, -5.2498e-01],\n",
       "         [-3.0184e-01, -9.9168e-02,  8.8200e-01, -2.0520e-01, -1.4474e-02,\n",
       "          -3.2591e-01, -1.3023e-01, -5.0654e-01, -1.9118e-02,  5.1749e-01,\n",
       "          -3.1310e-01,  8.4140e-02,  7.0855e-01,  6.1491e-01,  1.2291e-01,\n",
       "           9.1227e-02, -4.8618e-01, -1.8442e-01,  4.2619e-01, -7.8083e-01],\n",
       "         [-2.3931e-01, -6.9998e-02,  6.7546e-01, -1.7140e-01, -1.4406e-02,\n",
       "          -2.7869e-01, -4.8285e-02, -3.9707e-01, -3.4573e-02,  4.4059e-01,\n",
       "          -2.2774e-01,  9.6253e-02,  5.4360e-01,  4.7977e-01,  1.2894e-01,\n",
       "           3.6991e-02, -3.8351e-01, -1.6550e-01,  3.2340e-01, -6.1354e-01],\n",
       "         [-3.0109e-01, -9.7669e-02,  8.7999e-01, -2.0755e-01, -1.3854e-02,\n",
       "          -3.2692e-01, -1.3398e-01, -5.0795e-01, -1.9025e-02,  5.1884e-01,\n",
       "          -3.1324e-01,  8.5777e-02,  7.0474e-01,  6.1579e-01,  1.2321e-01,\n",
       "           9.2908e-02, -4.8712e-01, -1.8326e-01,  4.2265e-01, -7.7780e-01],\n",
       "         [-3.0104e-01, -9.5842e-02,  8.8156e-01, -2.0818e-01, -1.4143e-02,\n",
       "          -3.2613e-01, -1.3130e-01, -5.0533e-01, -2.1143e-02,  5.1662e-01,\n",
       "          -3.0987e-01,  8.8826e-02,  7.0534e-01,  6.1113e-01,  1.2214e-01,\n",
       "           9.0714e-02, -4.8481e-01, -1.8824e-01,  4.2299e-01, -7.7838e-01],\n",
       "         [-2.4756e-01, -6.8728e-02,  7.1737e-01, -1.7696e-01, -2.7721e-02,\n",
       "          -2.5965e-01, -1.0324e-01, -4.0017e-01, -2.6780e-02,  4.3418e-01,\n",
       "          -2.2775e-01,  9.8679e-02,  5.4670e-01,  4.4813e-01,  9.1909e-02,\n",
       "           7.4593e-02, -3.7035e-01, -1.9156e-01,  3.1036e-01, -6.0883e-01],\n",
       "         [-2.6877e-01, -1.0111e-01,  7.5177e-01, -1.7947e-01,  1.0113e-03,\n",
       "          -2.8070e-01, -1.0041e-01, -4.4040e-01, -9.9266e-03,  4.5482e-01,\n",
       "          -2.6766e-01,  5.4070e-02,  6.4785e-01,  5.5036e-01,  8.6410e-02,\n",
       "           5.4648e-02, -4.4898e-01, -1.7681e-01,  3.8990e-01, -7.0208e-01],\n",
       "         [-3.0072e-01, -9.7285e-02,  8.8153e-01, -2.0761e-01, -1.3351e-02,\n",
       "          -3.2694e-01, -1.3283e-01, -5.0760e-01, -2.0100e-02,  5.1766e-01,\n",
       "          -3.1298e-01,  8.6813e-02,  7.0587e-01,  6.1461e-01,  1.2345e-01,\n",
       "           9.2242e-02, -4.8600e-01, -1.8446e-01,  4.2456e-01, -7.7877e-01]],\n",
       "\n",
       "        [[-3.3918e-01,  4.4645e-02,  1.0547e+00, -1.9971e-01, -3.1099e-04,\n",
       "          -4.4488e-01, -1.7998e-01, -4.4795e-01, -1.6365e-01,  6.5678e-01,\n",
       "          -3.0477e-01,  2.5017e-01,  5.6418e-01,  5.4605e-01,  2.7651e-01,\n",
       "           1.5538e-01, -3.2420e-01, -1.7560e-01,  4.3852e-01, -7.1349e-01],\n",
       "         [-3.0513e-01,  2.6428e-02,  7.4197e-01, -1.9563e-01,  1.8793e-02,\n",
       "          -3.1932e-01, -6.9417e-02, -3.0397e-01, -1.4816e-01,  4.5174e-01,\n",
       "          -2.2900e-01,  1.7902e-01,  4.4545e-01,  4.1345e-01,  2.1070e-01,\n",
       "           1.1351e-01, -2.6765e-01, -1.8348e-01,  3.2539e-01, -5.4934e-01],\n",
       "         [-3.3979e-01,  4.4652e-02,  1.0550e+00, -1.9871e-01,  1.6500e-03,\n",
       "          -4.4417e-01, -1.7846e-01, -4.4678e-01, -1.6700e-01,  6.5428e-01,\n",
       "          -3.0681e-01,  2.5177e-01,  5.6318e-01,  5.4597e-01,  2.7847e-01,\n",
       "           1.5518e-01, -3.2245e-01, -1.7663e-01,  4.3852e-01, -7.1388e-01],\n",
       "         [-3.0580e-01,  3.4467e-02,  9.5481e-01, -1.8742e-01, -7.9064e-03,\n",
       "          -4.1487e-01, -1.3381e-01, -4.2454e-01, -1.4158e-01,  6.3045e-01,\n",
       "          -2.8890e-01,  2.2489e-01,  4.9872e-01,  5.0524e-01,  2.5927e-01,\n",
       "           1.1625e-01, -3.2335e-01, -1.5896e-01,  3.8959e-01, -6.5489e-01],\n",
       "         [-3.4004e-01,  4.3877e-02,  1.0522e+00, -2.0147e-01,  1.9246e-04,\n",
       "          -4.4388e-01, -1.7639e-01, -4.4605e-01, -1.6467e-01,  6.5455e-01,\n",
       "          -3.0477e-01,  2.5049e-01,  5.6501e-01,  5.4514e-01,  2.7780e-01,\n",
       "           1.5444e-01, -3.2339e-01, -1.7747e-01,  4.3759e-01, -7.1370e-01],\n",
       "         [-3.2476e-01,  3.7443e-02,  8.9373e-01, -1.8655e-01,  1.4583e-02,\n",
       "          -3.9541e-01, -1.4458e-01, -3.9393e-01, -1.5638e-01,  5.6582e-01,\n",
       "          -2.7434e-01,  2.0928e-01,  5.1376e-01,  4.9148e-01,  2.4791e-01,\n",
       "           1.4261e-01, -2.9537e-01, -1.7133e-01,  3.9095e-01, -6.5134e-01],\n",
       "         [-3.0818e-01,  3.4168e-02,  9.5033e-01, -1.9015e-01, -7.6444e-03,\n",
       "          -4.1328e-01, -1.2949e-01, -4.2217e-01, -1.4225e-01,  6.2855e-01,\n",
       "          -2.8733e-01,  2.2372e-01,  4.9835e-01,  5.0398e-01,  2.5757e-01,\n",
       "           1.1553e-01, -3.2594e-01, -1.6223e-01,  3.8842e-01, -6.5384e-01],\n",
       "         [-2.5398e-01,  1.0921e-02,  8.5642e-01, -1.6056e-01,  1.1310e-02,\n",
       "          -3.4945e-01, -1.8222e-01, -3.8343e-01, -1.4271e-01,  5.1745e-01,\n",
       "          -2.7259e-01,  1.9823e-01,  5.0593e-01,  4.2394e-01,  2.1185e-01,\n",
       "           1.5251e-01, -2.4639e-01, -1.5848e-01,  3.7910e-01, -5.9877e-01],\n",
       "         [-2.8817e-01,  3.2368e-02,  9.6829e-01, -1.6194e-01,  3.0549e-03,\n",
       "          -4.0772e-01, -1.7912e-01, -4.2278e-01, -1.6582e-01,  6.0825e-01,\n",
       "          -2.9380e-01,  2.4480e-01,  5.1829e-01,  4.8457e-01,  2.6360e-01,\n",
       "           1.4390e-01, -2.6613e-01, -1.6075e-01,  4.0371e-01, -6.6205e-01],\n",
       "         [-3.2758e-01,  3.5930e-02,  9.0207e-01, -1.8772e-01,  1.4712e-02,\n",
       "          -3.9656e-01, -1.4853e-01, -3.9658e-01, -1.5712e-01,  5.6625e-01,\n",
       "          -2.7798e-01,  2.1052e-01,  5.1782e-01,  4.9512e-01,  2.4643e-01,\n",
       "           1.4574e-01, -2.9783e-01, -1.7376e-01,  3.9373e-01, -6.5522e-01]]],\n",
       "       grad_fn=<BmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_head = AttentionHead(20, 20)\n",
    "attn_head(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multi-head attention block simply applies multiple attention heads, then concatenates the outputs and applies a single linear projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll supress logging from the scaled dot product attention now\n",
    "logger.setLevel(TensorLoggingLevels.attention_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    level = TensorLoggingLevels.multihead_attention_block\n",
    "    def __init__(self, d_model, d_feature, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_feature = d_feature\n",
    "        self.n_heads = n_heads\n",
    "        # in practice, d_model == d_feature * n_heads\n",
    "        assert d_model == d_feature * n_heads\n",
    "\n",
    "        # Note that this is very inefficient:\n",
    "        # I am merely implementing the heads separately because it is \n",
    "        # easier to understand this way\n",
    "        self.attn_heads = nn.ModuleList([\n",
    "            AttentionHead(d_model, d_feature, dropout) for _ in range(n_heads)\n",
    "        ])\n",
    "        self.projection = nn.Linear(d_feature * n_heads, d_model) \n",
    "    \n",
    "    def forward(self, queries, keys, values, mask=None):\n",
    "        log_size(queries, \"Input queries\")\n",
    "        x = [attn(queries, keys, values, mask=mask) # (Batch, Seq, Feature)\n",
    "             for i, attn in enumerate(self.attn_heads)]\n",
    "        log_size(x[0], \"output of single head\")\n",
    "        \n",
    "        # reconcatenate\n",
    "        x = torch.cat(x, dim=Dim.feature) # (Batch, Seq, D_Feature * n_heads)\n",
    "        log_size(x, \"concatenated output\")\n",
    "        x = self.projection(x) # (Batch, Seq, D_Model)\n",
    "        log_size(x, \"projected output\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MultiHeadAttention] Input queries size=torch.Size([5, 10, 160])\n",
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries, keys, vals size=torch.Size([5, 10, 20])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 10, 20])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 160])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 160])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3042,  0.1619,  0.0106,  ..., -0.1427,  0.0059,  0.1014],\n",
       "         [ 0.2979,  0.1736,  0.0117,  ..., -0.1062,  0.0062,  0.1129],\n",
       "         [ 0.2891,  0.1671, -0.0147,  ..., -0.0910,  0.0428,  0.1291],\n",
       "         ...,\n",
       "         [ 0.2688,  0.1477, -0.0178,  ..., -0.0798,  0.0340,  0.1409],\n",
       "         [ 0.2719,  0.2131, -0.0258,  ..., -0.1069,  0.0571,  0.1530],\n",
       "         [ 0.3113,  0.1642, -0.0201,  ..., -0.1078,  0.0338,  0.1403]],\n",
       "\n",
       "        [[ 0.3256,  0.0920, -0.0382,  ..., -0.0416, -0.0111,  0.1374],\n",
       "         [ 0.3092,  0.1090, -0.0048,  ..., -0.0738, -0.0060,  0.1081],\n",
       "         [ 0.3076,  0.1170, -0.0270,  ..., -0.0978,  0.0117,  0.1132],\n",
       "         ...,\n",
       "         [ 0.3159,  0.1064, -0.0193,  ..., -0.0508, -0.0045,  0.0988],\n",
       "         [ 0.3430,  0.0834, -0.0113,  ..., -0.0589, -0.0063,  0.1070],\n",
       "         [ 0.3304,  0.0820, -0.0062,  ..., -0.0756, -0.0149,  0.0951]],\n",
       "\n",
       "        [[ 0.2724,  0.1273, -0.0339,  ..., -0.0428,  0.0219,  0.1351],\n",
       "         [ 0.3204,  0.1184,  0.0022,  ..., -0.0482, -0.0166,  0.0907],\n",
       "         [ 0.3198,  0.1569, -0.0297,  ..., -0.0539, -0.0194,  0.1301],\n",
       "         ...,\n",
       "         [ 0.3344,  0.1191,  0.0096,  ..., -0.0594, -0.0073,  0.1197],\n",
       "         [ 0.3139,  0.1653, -0.0145,  ..., -0.0898, -0.0096,  0.1197],\n",
       "         [ 0.2867,  0.1438, -0.0332,  ..., -0.0770, -0.0317,  0.0784]],\n",
       "\n",
       "        [[ 0.2922,  0.1451,  0.0140,  ..., -0.0751, -0.0058,  0.0466],\n",
       "         [ 0.3430,  0.1043,  0.0169,  ..., -0.0573, -0.0371,  0.0515],\n",
       "         [ 0.3260,  0.1380, -0.0006,  ..., -0.0714, -0.0032,  0.0573],\n",
       "         ...,\n",
       "         [ 0.2850,  0.1119,  0.0044,  ..., -0.0538, -0.0272,  0.0277],\n",
       "         [ 0.3128,  0.1419, -0.0095,  ..., -0.0906, -0.0223,  0.0409],\n",
       "         [ 0.3284,  0.1321,  0.0137,  ..., -0.1217, -0.0386,  0.0233]],\n",
       "\n",
       "        [[ 0.3367,  0.1072, -0.0104,  ..., -0.0605, -0.0384,  0.0228],\n",
       "         [ 0.3384,  0.1186, -0.0061,  ..., -0.0553, -0.0180,  0.0256],\n",
       "         [ 0.3194,  0.1342, -0.0129,  ..., -0.0699, -0.0416,  0.0009],\n",
       "         ...,\n",
       "         [ 0.3338,  0.1137, -0.0077,  ..., -0.0464, -0.0524,  0.0343],\n",
       "         [ 0.2795,  0.1230, -0.0154,  ..., -0.0242, -0.0100,  0.0469],\n",
       "         [ 0.3120,  0.1037, -0.0166,  ..., -0.0277, -0.0268,  0.0177]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads = MultiHeadAttention(20 * 8, 20, 8)\n",
    "heads(q.repeat(1, 1, 8), \n",
    "      k.repeat(1, 1, 8), \n",
    "      v.repeat(1, 1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these core components in place, implementing the encoder is pretty easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i2.wp.com/mlexplained.com/wp-content/uploads/2017/12/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2017-12-29-19.14.41.png?w=273)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder consists of the following components:\n",
    "- A multi-head attention block\n",
    "- A simple feedforward neural network\n",
    "\n",
    "These components are connected using residual connections and layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll supress logging from the individual attention heads\n",
    "logger.setLevel(TensorLoggingLevels.multihead_attention_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer normalization is similar to batch normalization, but normalizes across the feature dimension instead of the batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i1.wp.com/mlexplained.com/wp-content/uploads/2018/01/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2018-01-11-11.48.12.png?w=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-8):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder just stacks these together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    level = TensorLoggingLevels.enc_dec_block\n",
    "    def __init__(self, d_model=512, d_feature=64,\n",
    "                 d_ff=2048, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.layer_norm1 = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.position_wise_feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "        self.layer_norm2 = LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        log_size(x, \"Encoder block input\")\n",
    "        att = self.attn_head(x, x, x, mask=mask)\n",
    "        log_size(x, \"Attention output\")\n",
    "        # Apply normalization and residual connection\n",
    "        x = x + self.dropout(self.layer_norm1(att))\n",
    "        # Apply position-wise feedforward network\n",
    "        pos = self.position_wise_feed_forward(x)\n",
    "        log_size(x, \"Feedforward output\")\n",
    "        # Apply normalization and residual connection\n",
    "        x = x + self.dropout(self.layer_norm2(pos))\n",
    "        log_size(x, \"Encoder size output\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = EncoderBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EncoderBlock] Encoder block input size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 10, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 10, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.5778e-01,  1.2996e-01, -2.0364e+00,  ...,  9.2855e-01,\n",
       "           3.0538e-01, -1.9435e+00],\n",
       "         [ 1.7227e+00, -1.8700e-01, -1.9670e+00,  ...,  1.5087e+00,\n",
       "           1.0436e+00,  4.1258e-02],\n",
       "         [ 1.2205e+00, -2.2935e-02, -2.5246e+00,  ...,  2.7623e+00,\n",
       "           2.8276e-02, -3.0901e+00],\n",
       "         ...,\n",
       "         [ 7.7646e-01, -4.2103e-01, -1.8793e-01,  ...,  1.0549e+00,\n",
       "           9.1001e-01,  2.9219e-02],\n",
       "         [ 6.2856e-01,  6.0925e-01, -2.1385e+00,  ...,  2.0138e+00,\n",
       "           6.0836e-01, -2.4650e+00],\n",
       "         [ 1.3225e+00, -6.8761e-01, -1.4338e+00,  ...,  2.3427e+00,\n",
       "           9.0309e-01, -1.8249e+00]],\n",
       "\n",
       "        [[ 1.9393e+00, -3.6200e-03, -2.3605e+00,  ...,  1.7602e+00,\n",
       "           8.6034e-01,  3.1441e-01],\n",
       "         [ 1.1189e+00,  6.1461e-02, -1.6022e+00,  ...,  2.7324e+00,\n",
       "           7.8264e-01, -3.3045e+00],\n",
       "         [ 2.1796e-01,  3.5294e-02, -2.7486e+00,  ...,  3.2831e-01,\n",
       "          -4.0683e-02, -2.8061e+00],\n",
       "         ...,\n",
       "         [ 1.4822e+00, -8.7679e-01, -1.6299e+00,  ...,  2.0062e+00,\n",
       "           7.2703e-01, -1.6604e+00],\n",
       "         [-5.2170e-02,  7.6570e-01, -6.9542e-01,  ...,  2.5439e+00,\n",
       "           2.1008e+00, -2.7337e+00],\n",
       "         [ 1.0253e+00,  3.6480e-01, -1.8318e+00,  ...,  2.6684e+00,\n",
       "           5.5661e-01, -3.0573e+00]],\n",
       "\n",
       "        [[ 7.6064e-01, -1.2754e-01, -1.5771e+00,  ...,  2.6170e+00,\n",
       "           2.4607e-01, -2.2668e+00],\n",
       "         [ 3.2214e-01, -9.4836e-01, -2.2023e+00,  ...,  2.8692e+00,\n",
       "           6.0909e-02, -3.9965e+00],\n",
       "         [ 8.8579e-01, -7.4389e-01, -2.1118e+00,  ...,  2.4180e+00,\n",
       "           1.4007e+00, -2.8221e+00],\n",
       "         ...,\n",
       "         [ 5.5374e-01,  6.3389e-01,  2.8300e-01,  ...,  2.5808e+00,\n",
       "           1.5383e+00, -1.6487e+00],\n",
       "         [-1.0599e-01, -5.8665e-02, -1.3827e+00,  ...,  2.1332e+00,\n",
       "          -4.1162e-01, -2.4157e+00],\n",
       "         [ 1.1639e+00, -6.6003e-01, -1.4095e+00,  ...,  3.4886e+00,\n",
       "          -5.6218e-02, -2.9218e+00]],\n",
       "\n",
       "        [[-1.3494e-01, -4.4064e-01, -2.1613e+00,  ...,  2.1785e+00,\n",
       "           1.0776e-01, -2.5259e+00],\n",
       "         [-6.4119e-02, -4.6954e-01, -1.7466e+00,  ...,  1.7297e+00,\n",
       "          -1.4451e+00, -2.7153e+00],\n",
       "         [ 2.5346e-01, -7.1763e-03, -1.3512e+00,  ...,  1.4894e+00,\n",
       "          -1.6615e+00, -2.3902e+00],\n",
       "         ...,\n",
       "         [-1.8592e-01, -6.3331e-02, -2.2454e+00,  ...,  1.5071e+00,\n",
       "           1.5555e+00,  4.5454e-02],\n",
       "         [ 1.2861e-01,  8.1488e-01, -2.2194e+00,  ...,  1.7994e+00,\n",
       "          -3.8170e-01, -3.2874e+00],\n",
       "         [-1.7124e-02, -1.5101e-01, -1.9465e+00,  ...,  2.6310e+00,\n",
       "           5.4292e-01, -3.3550e+00]],\n",
       "\n",
       "        [[ 1.4940e-01, -1.5006e+00, -1.7297e+00,  ...,  3.7078e+00,\n",
       "           2.4054e-01, -2.5284e+00],\n",
       "         [ 9.7613e-01,  2.7719e-02,  2.8498e-01,  ...,  2.7890e+00,\n",
       "           4.5289e-01, -1.0859e+00],\n",
       "         [ 1.4985e+00,  3.1828e-01, -1.6670e+00,  ...,  2.8453e+00,\n",
       "           8.1162e-01, -1.6027e+00],\n",
       "         ...,\n",
       "         [-2.3145e-01, -7.4511e-01, -2.3555e+00,  ...,  4.8571e-01,\n",
       "           3.9324e-01, -1.8448e+00],\n",
       "         [ 7.7950e-01, -6.1996e-01, -2.3353e+00,  ...,  2.9027e+00,\n",
       "           8.4805e-01, -1.7644e+00],\n",
       "         [ 1.3845e+00,  8.8271e-02, -2.1779e+00,  ...,  3.2629e+00,\n",
       "          -1.6899e+00, -2.3054e+00]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(torch.rand(5, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder consists of 6 consecutive encoder blocks, so can simply be implemented like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    level = TensorLoggingLevels.enc_dec\n",
    "    def __init__(self, n_blocks=6, d_model=512,\n",
    "                 n_heads=8, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoders = nn.ModuleList([\n",
    "            EncoderBlock(d_model=d_model, d_feature=d_model // n_heads,\n",
    "                         d_ff=d_ff, dropout=dropout)\n",
    "            for _ in range(n_blocks)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x: torch.FloatTensor, mask=None):\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder is mostly the same as the encoder. There's just one additional multi-head attention block that takes the target sentence as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i1.wp.com/mlexplained.com/wp-content/uploads/2017/12/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2017-12-29-19.14.47.png?w=287)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys and values are the outputs of the encoder, and the queries are the outputs of the multi-head attention over the target entence embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    level = TensorLoggingLevels.enc_dec_block\n",
    "    def __init__(self, d_model=512, d_feature=64,\n",
    "                 d_ff=2048, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.masked_attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.position_wise_feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "\n",
    "        self.layer_norm1 = LayerNorm(d_model)\n",
    "        self.layer_norm2 = LayerNorm(d_model)\n",
    "        self.layer_norm3 = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_out, \n",
    "                src_mask=None, tgt_mask=None):\n",
    "        # Apply attention to inputs\n",
    "        att = self.masked_attn_head(x, x, x, mask=src_mask)\n",
    "        x = x + self.dropout(self.layer_norm1(att))\n",
    "        # Apply attention to the encoder outputs and outputs of the previous layer\n",
    "        att = self.attn_head(queries=x, keys=enc_out, values=enc_out, mask=tgt_mask)\n",
    "        x = x + self.dropout(self.layer_norm2(att))\n",
    "        # Apply position-wise feedforward network\n",
    "        pos = self.position_wise_feed_forward(x)\n",
    "        x = x + self.dropout(self.layer_norm2(pos))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EncoderBlock] Encoder block input size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 10, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 10, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 10, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6580,  1.6086,  2.2659,  ..., -1.1474,  1.6117, -0.2441],\n",
       "         [ 2.4482, -0.9475,  1.9422,  ..., -1.0947,  0.6952,  0.7469],\n",
       "         [ 1.5224,  0.5489,  1.5800,  ...,  0.1848,  1.8750,  0.6865],\n",
       "         ...,\n",
       "         [ 1.5526, -0.5386,  0.2448,  ..., -1.5395,  0.8934, -0.2828],\n",
       "         [ 2.1378,  0.9989,  1.6901,  ...,  0.7147,  1.6487, -0.5346],\n",
       "         [ 1.7555,  0.1182,  1.9243,  ..., -0.6435,  1.5094,  0.7406]],\n",
       "\n",
       "        [[ 2.3763,  0.2463,  1.3593,  ..., -0.6498,  1.9941,  0.2738],\n",
       "         [ 2.2653,  0.3445,  1.4671,  ..., -1.0508,  1.6819,  0.6277],\n",
       "         [ 1.2639, -0.7048,  1.5885,  ...,  0.7334,  2.5985, -0.2863],\n",
       "         ...,\n",
       "         [ 1.9279, -0.3174,  2.3046,  ..., -1.0829,  1.9061,  1.3080],\n",
       "         [ 1.3932, -0.2881,  1.0695,  ...,  0.2407,  2.4994,  0.3057],\n",
       "         [ 1.7608,  0.2705,  1.4249,  ...,  0.1931,  2.0356,  0.5568]],\n",
       "\n",
       "        [[ 1.6962, -0.1480,  1.3472,  ..., -0.8366,  1.8088,  0.7894],\n",
       "         [ 1.3533, -0.8355,  1.2008,  ..., -0.8133,  0.6901,  0.3011],\n",
       "         [ 1.2053, -0.4317,  0.8909,  ..., -1.6726,  1.3605,  0.9532],\n",
       "         ...,\n",
       "         [ 1.6551, -0.1179,  1.2438,  ..., -1.4427,  1.4958,  0.7380],\n",
       "         [ 0.5604,  0.4291,  0.3245,  ...,  0.0240,  1.2656,  1.1208],\n",
       "         [ 1.7551, -0.4755,  1.1139,  ..., -1.0155,  0.2043,  1.3263]],\n",
       "\n",
       "        [[ 1.5647, -0.2625,  1.7680,  ..., -1.4272,  0.7970,  2.1156],\n",
       "         [ 2.2871, -1.2370,  1.3372,  ..., -0.4329,  1.5552,  0.8705],\n",
       "         [ 2.0724,  0.4931,  0.5943,  ..., -0.9830,  1.5505,  0.0410],\n",
       "         ...,\n",
       "         [ 1.1387,  0.4475,  2.0640,  ..., -0.1829,  0.8859,  0.6355],\n",
       "         [ 1.5635, -0.0336,  0.7009,  ..., -1.1748,  0.3840,  1.3769],\n",
       "         [ 1.9762, -0.0938,  1.6708,  ..., -0.9659,  0.4148,  2.0147]],\n",
       "\n",
       "        [[ 1.3606,  0.2749,  1.5843,  ..., -0.6447,  1.4815,  0.6186],\n",
       "         [ 1.5377,  0.7145,  1.8820,  ..., -0.5187,  1.4177, -0.2994],\n",
       "         [ 0.3875,  0.8642,  2.1695,  ..., -0.9347,  2.4947,  0.1224],\n",
       "         ...,\n",
       "         [ 0.8587,  0.8280,  2.6113,  ..., -0.8377,  1.2526,  1.2799],\n",
       "         [ 2.0980,  1.4562,  0.6987,  ..., -1.1976,  1.8787,  0.4398],\n",
       "         [ 0.9718,  0.0466,  1.3624,  ..., -0.2978,  0.8781,  0.4406]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = DecoderBlock()\n",
    "dec(torch.rand(5, 10, 512), enc(torch.rand(5, 10, 512)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the decoder is just a stack of the underlying block so is simple to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    level = TensorLoggingLevels.enc_dec\n",
    "    def __init__(self, n_blocks=6, d_model=512, d_feature=64,\n",
    "                 d_ff=2048, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "        self.decoders = nn.ModuleList([\n",
    "            DecoderBlock(d_model=d_model, d_feature=d_model // n_heads,\n",
    "                         d_ff=d_ff, dropout=dropout)\n",
    "            for _ in range(n_blocks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x: torch.FloatTensor, \n",
    "                enc_out: torch.FloatTensor, \n",
    "                src_mask=None, tgt_mask=None):\n",
    "        for decoder in self.decoders:\n",
    "            x = decoder(x, enc_out, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention blocks are just simple matrix multiplications: therefore they don't have any notion of order! The Transformer explicitly adds positional information via the positional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    level = 1\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.weight = nn.Parameter(pe, requires_grad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.weight[:, :x.size(1), :] # (1, Seq, Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordPositionEmbedding(nn.Module):\n",
    "    level = 1\n",
    "    def __init__(self, vocab_size, d_model=512):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "        \n",
    "    def forward(self, x: torch.LongTensor, mask=None) -> torch.FloatTensor:\n",
    "        return self.word_embedding(x) + self.position_embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = WordPositionEmbedding(1000)\n",
    "encoder = TransformerEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] Input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of single head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.9217e-01,  1.2299e+00,  3.3396e+00,  ..., -4.4087e-01,\n",
       "           5.5446e+00,  1.9942e+00],\n",
       "         [ 2.6970e+00, -1.0296e+00,  8.6089e+00,  ...,  2.3508e+00,\n",
       "           3.8681e+00,  1.0141e+00],\n",
       "         [-8.7528e-01,  5.3640e-01,  3.5934e+00,  ...,  1.9303e+00,\n",
       "           4.5249e+00,  6.1926e-01],\n",
       "         ...,\n",
       "         [-1.2338e+00, -7.6097e-01,  6.1613e+00,  ..., -1.5663e+00,\n",
       "           3.9485e+00,  2.4136e+00],\n",
       "         [-1.5244e-01,  8.5849e-01,  4.2663e+00,  ..., -1.2305e+00,\n",
       "           4.4364e+00, -6.5651e-01],\n",
       "         [-1.3939e+00,  2.2442e+00,  3.2477e+00,  ...,  2.9532e+00,\n",
       "           2.6887e+00, -1.9719e-01]],\n",
       "\n",
       "        [[ 1.0720e+00,  5.2130e+00, -1.9961e+00,  ..., -2.8311e+00,\n",
       "           3.1156e+00,  3.6057e+00],\n",
       "         [ 8.9173e-01,  1.8281e+00,  4.4644e+00,  ..., -2.8587e+00,\n",
       "           1.9145e+00,  8.4519e-01],\n",
       "         [ 2.6354e+00,  2.0722e+00, -9.4354e-01,  ..., -4.2711e+00,\n",
       "           2.7082e-01,  3.2981e+00],\n",
       "         ...,\n",
       "         [ 2.3612e+00, -3.5895e-01,  1.5528e+00,  ..., -9.1695e-03,\n",
       "          -3.8244e-01,  1.5372e+00],\n",
       "         [ 4.4529e-02,  8.2165e-01,  3.4588e+00,  ..., -2.9835e+00,\n",
       "           3.0511e+00, -1.4193e+00],\n",
       "         [ 2.0843e+00,  4.9858e+00,  1.4769e+00,  ...,  6.3511e-01,\n",
       "           2.8082e+00,  1.6657e+00]],\n",
       "\n",
       "        [[ 1.3085e+00,  1.5669e+00,  3.0106e+00,  ..., -3.4198e+00,\n",
       "           4.1705e+00, -1.0113e+00],\n",
       "         [ 9.0911e-01,  3.0690e+00,  5.4064e+00,  ..., -2.6327e+00,\n",
       "           3.0873e+00,  4.0103e+00],\n",
       "         [ 2.8316e+00,  2.5801e+00,  7.0824e+00,  ..., -1.8614e+00,\n",
       "           3.5982e+00,  3.8289e+00],\n",
       "         ...,\n",
       "         [ 2.2810e+00,  3.5775e+00,  5.0838e+00,  ...,  4.8906e-01,\n",
       "           4.5755e+00,  3.0964e+00],\n",
       "         [ 8.3524e-01,  3.4717e+00,  4.9068e+00,  ..., -7.4778e-01,\n",
       "           3.6191e+00,  2.0107e+00],\n",
       "         [-1.2423e+00,  1.5261e+00,  5.0316e+00,  ...,  2.7214e+00,\n",
       "           5.7117e+00,  4.8142e-01]],\n",
       "\n",
       "        [[ 9.4920e-01,  3.5174e+00,  2.4730e+00,  ..., -5.5234e-01,\n",
       "           3.4464e+00,  2.8197e+00],\n",
       "         [ 1.8126e+00,  2.3719e+00,  3.6678e+00,  ..., -3.6154e+00,\n",
       "           7.1922e+00, -3.7526e-01],\n",
       "         [ 2.7929e+00,  2.2172e+00, -9.4899e-01,  ..., -2.7179e+00,\n",
       "           1.5483e+00,  2.6857e+00],\n",
       "         ...,\n",
       "         [ 6.7794e+00,  8.3219e+00, -1.6162e+00,  ..., -3.6078e+00,\n",
       "           1.6753e+00,  7.5992e-03],\n",
       "         [ 4.9691e+00,  2.6229e+00,  6.3540e+00,  ..., -3.8763e+00,\n",
       "           7.2187e+00, -7.0004e-01],\n",
       "         [ 7.7854e-01, -1.4459e+00,  3.2058e+00,  ..., -6.2487e-01,\n",
       "           6.4867e+00, -1.7340e-01]],\n",
       "\n",
       "        [[ 2.0934e+00,  4.0377e+00,  3.8399e+00,  ..., -2.5042e-01,\n",
       "           1.5193e+00,  1.4931e+00],\n",
       "         [-3.4017e-01,  2.8364e+00,  5.8794e+00,  ..., -1.6688e+00,\n",
       "           3.4065e+00, -1.8511e+00],\n",
       "         [ 2.3294e+00,  3.4030e+00,  2.3506e+00,  ..., -1.6131e+00,\n",
       "           1.6325e+00,  1.7637e-01],\n",
       "         ...,\n",
       "         [ 1.9980e+00, -9.0088e-01,  2.3049e+00,  ..., -1.2428e+00,\n",
       "           2.8087e+00,  4.4368e+00],\n",
       "         [ 1.7799e+00,  1.7538e+00, -1.0066e+00,  ..., -5.6986e-01,\n",
       "           4.1194e+00,  1.1491e+00],\n",
       "         [ 2.5113e+00,  2.6135e+00,  3.2447e+00,  ...,  3.5168e+00,\n",
       "           2.7508e+00,  5.3784e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(emb(torch.randint(1000, (5, 30))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put everything together now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://camo.githubusercontent.com/88e8f36ce61dedfd2491885b8df2f68c4d1f92f5/687474703a2f2f696d6775722e636f6d2f316b72463252362e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll supress logging from the scaled dot product attention now\n",
    "logger.setLevel(TensorLoggingLevels.enc_dec_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = WordPositionEmbedding(1000)\n",
    "encoder = TransformerEncoder()\n",
    "decoder = TransformerDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9897, -0.6359, -4.6231,  ...,  6.9500, -2.5999, -1.1461],\n",
       "         [ 4.7274,  2.4179, -1.3643,  ...,  3.7251, -5.0835, -1.2877],\n",
       "         [ 1.3116, -2.8317, -0.4552,  ...,  6.3076, -2.6063, -1.2082],\n",
       "         ...,\n",
       "         [-1.6635,  1.0923, -3.2574,  ...,  5.4824,  7.1426, -1.6863],\n",
       "         [-5.4686, -5.1602,  2.1902,  ...,  4.9131, -0.5623, -1.3769],\n",
       "         [-2.0100, -0.0638, -0.5601,  ...,  8.5894, -5.7065, -1.6143]],\n",
       "\n",
       "        [[ 3.1028,  2.0424,  3.1762,  ...,  4.8382,  0.1979, -1.9995],\n",
       "         [ 6.9066,  2.4632, -0.3387,  ...,  7.5088,  3.6147, -1.4422],\n",
       "         [ 0.4897, -1.3431,  1.0123,  ...,  7.9888, -1.5388,  0.0488],\n",
       "         ...,\n",
       "         [ 4.1120, -0.1403,  4.1639,  ...,  7.6805, -2.7701, -3.9894],\n",
       "         [ 4.0688, -0.4527,  6.4777,  ...,  8.5668,  1.8083, -2.8293],\n",
       "         [ 1.0619, -0.8440,  4.5008,  ...,  7.7869, -0.6064, -5.2547]],\n",
       "\n",
       "        [[ 3.5427, -2.0393, -5.0770,  ...,  8.2788, -0.4944, -0.8862],\n",
       "         [ 4.2967,  0.6085, -2.1398,  ...,  6.9309, -1.4336, -1.7265],\n",
       "         [-1.1239,  0.2275,  1.1091,  ..., 10.6476,  3.4010, -1.3729],\n",
       "         ...,\n",
       "         [ 2.9773, -0.4642, -1.0522,  ...,  9.8407,  2.3485, -3.2426],\n",
       "         [-5.1316, -4.0544,  1.0321,  ...,  7.1439, -0.4071,  0.4098],\n",
       "         [-2.8505, -1.4631, -2.8762,  ..., 11.5245, -3.3351,  0.1060]],\n",
       "\n",
       "        [[ 1.1068,  5.0667,  1.1881,  ...,  8.0960, -2.9043, -2.7200],\n",
       "         [ 2.8451,  3.6228, -0.4716,  ..., 12.3087, -3.5072, -3.2373],\n",
       "         [ 1.2044,  1.8325, -2.9469,  ...,  9.5245, -5.0704, -4.2772],\n",
       "         ...,\n",
       "         [ 5.2956,  3.6729,  2.4937,  ...,  8.9949, -2.6118, -2.2258],\n",
       "         [ 3.5791, -0.7363, -3.0650,  ...,  7.7620,  1.5963, -0.3880],\n",
       "         [ 2.4325,  0.3991,  0.4011,  ...,  6.6261,  2.1113, -0.4773]],\n",
       "\n",
       "        [[-0.0549, -0.6268, -1.2888,  ...,  5.2033, -0.6122, -1.6698],\n",
       "         [-1.4933, -4.9630,  0.1711,  ...,  5.6724, -1.7991,  1.6420],\n",
       "         [-0.8708,  2.8582,  2.7742,  ...,  4.2308, -4.8847,  1.5685],\n",
       "         ...,\n",
       "         [-2.3626, -1.3120, -0.1416,  ...,  9.6258, -1.6555, -2.7510],\n",
       "         [-1.1036, -5.6005,  2.8954,  ...,  4.5143, -4.2567, -2.4123],\n",
       "         [-2.9271, -4.8427,  2.1443,  ..., 10.4210, -0.6207, -2.6060]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_ids = torch.randint(1000, (5, 30))\n",
    "tgt_ids = torch.randint(1000, (5, 30))\n",
    "x = encoder(emb(src_ids))\n",
    "decoder(emb(tgt_ids), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
